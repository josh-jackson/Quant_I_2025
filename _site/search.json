[
  {
    "objectID": "Basics_1.html#glm",
    "href": "Basics_1.html#glm",
    "title": "What are models?",
    "section": "GLM",
    "text": "GLM\n\nGeneral(ized) Linear Model\nA workhorse that is responsible for &gt;99% of statistical tests in psychology, as well as the building block of many machine learning models"
  },
  {
    "objectID": "Basics_1.html#what-do-we-mean-by-generalized",
    "href": "Basics_1.html#what-do-we-mean-by-generalized",
    "title": "What are models?",
    "section": "What do we mean by General(ized)?",
    "text": "What do we mean by General(ized)?\n\nIt is general in that it refers to a broad set of similar models that can applied to almost any context"
  },
  {
    "objectID": "Basics_1.html#what-do-we-mean-by-linear",
    "href": "Basics_1.html#what-do-we-mean-by-linear",
    "title": "What are models?",
    "section": "What do we mean by linear?",
    "text": "What do we mean by linear?\n\nWe try to understand our dependent variable (DV) via a linear combination predictor variables.\nA linear combination a way of combining things (variables) using scalar multiplication and addition"
  },
  {
    "objectID": "Basics_1.html#what-is-a-model",
    "href": "Basics_1.html#what-is-a-model",
    "title": "What are models?",
    "section": "What is a model?",
    "text": "What is a model?"
  },
  {
    "objectID": "Basics_1.html#what-is-a-model-1",
    "href": "Basics_1.html#what-is-a-model-1",
    "title": "What are models?",
    "section": "What is a model?",
    "text": "What is a model?\n\na representation of the world\na statistical model uses math to make predictions about the world"
  },
  {
    "objectID": "Basics_1.html#middle-school-math",
    "href": "Basics_1.html#middle-school-math",
    "title": "What are models?",
    "section": "Middle School Math",
    "text": "Middle School Math\n\\[ y = mx + b \\] - what is \\(y\\)?\n\nwhat is \\(m\\)?\nwhat is \\(x\\)?\nwhat is \\(b\\)?"
  },
  {
    "objectID": "Basics_1.html#lets-rewrite-this",
    "href": "Basics_1.html#lets-rewrite-this",
    "title": "What are models?",
    "section": "Let’s rewrite this",
    "text": "Let’s rewrite this\n\\[y = b_0 + b_{1}X\\]\n\nwhat is \\(y\\)?\nwhat is \\(b_0\\)?\nwhat is \\(b_1\\)?\nwhat is \\(X\\)?"
  },
  {
    "objectID": "Basics_1.html#are-models-always-right",
    "href": "Basics_1.html#are-models-always-right",
    "title": "What are models?",
    "section": "Are models always right?",
    "text": "Are models always right?"
  },
  {
    "objectID": "Basics_1.html#models-are-flawed",
    "href": "Basics_1.html#models-are-flawed",
    "title": "What are models?",
    "section": "MODELS ARE FLAWED",
    "text": "MODELS ARE FLAWED\n\nHow do we compensate?"
  },
  {
    "objectID": "Basics_1.html#models-are-flawed-1",
    "href": "Basics_1.html#models-are-flawed-1",
    "title": "What are models?",
    "section": "MODELS ARE FLAWED",
    "text": "MODELS ARE FLAWED\n\nHow do we compensate?\n\n\\(y = b_0 + b_{1}X + e\\)"
  },
  {
    "objectID": "Basics_1.html#models",
    "href": "Basics_1.html#models",
    "title": "What are models?",
    "section": "Models",
    "text": "Models\n\nWhat are the goals of modeling?\nWhat do you need in order to develop a model?"
  },
  {
    "objectID": "Basics_1.html#how-do-we-know-if-a-model-is-good",
    "href": "Basics_1.html#how-do-we-know-if-a-model-is-good",
    "title": "What are models?",
    "section": "How do we know if a model is good?",
    "text": "How do we know if a model is good?\n\nWhat makes it good?"
  },
  {
    "objectID": "Basics_1.html#how-will-we-use-models",
    "href": "Basics_1.html#how-will-we-use-models",
    "title": "What are models?",
    "section": "How will we use models?",
    "text": "How will we use models?\n\nThis semester, we will mainly focus on classic statistical tests\nEvery single one of these is a model\nWe will also focus on developing your intuition\nWhen you face new models, come back to these basics"
  },
  {
    "objectID": "Basics_1.html#how-can-we-visualize-data-to-make-sense-of-it",
    "href": "Basics_1.html#how-can-we-visualize-data-to-make-sense-of-it",
    "title": "What are models?",
    "section": "How can we visualize data to make sense of it?",
    "text": "How can we visualize data to make sense of it?\n\n\nCode\nlibrary(broom)\nset.seed(123)\nx.1 &lt;- rnorm(100, 0, 1)\ne.1 &lt;- rnorm(100, 0, 2)\ny.1 &lt;- .5 + .55 * x.1 + e.1\nd.1 &lt;- data.frame(x.1,y.1)\nm.1 &lt;- lm(y.1 ~ x.1, data = d.1)\nd1.f&lt;- augment(m.1)\nd.1\n\n\n             x.1         y.1\n1   -0.560475647 -1.22907473\n2   -0.230177489  0.88716980\n3    1.558708314  0.86390582\n4    0.070508391 -0.15630558\n5    0.129287735 -1.33212888\n6    1.715064987  1.35323029\n7    0.460916206 -0.81630503\n8   -1.265061235 -3.53166755\n9   -0.686852852 -0.63822211\n10  -0.445661970  2.09287913\n11   1.224081797  0.02255106\n12   0.359813827  1.91382625\n13   0.400771451 -2.51534112\n14   0.110682716  0.44975156\n15  -0.555841135  1.23310178\n16   1.786913137  2.08510895\n17   0.497850478  0.98517015\n18  -1.966617157 -1.86305145\n19   0.701355902 -0.81366295\n20  -0.472791408 -1.80829286\n21  -1.067823706  0.14799016\n22  -0.217974915 -1.51483543\n23  -1.026004448 -1.04541733\n24  -0.728891229 -0.41307456\n25  -0.625039268  3.84395241\n26  -1.686693311 -1.73158112\n27   0.837787044  1.43155602\n28   0.153373118  0.74027691\n29  -1.138136937 -2.04968858\n30   1.253814921  1.04698203\n31   0.426464221  3.62365704\n32  -0.295071483  1.24071879\n33   0.895125661  1.07478496\n34   0.878133488  0.13797975\n35   0.821581082 -3.15462485\n36   0.688640254  3.14142657\n37   0.553917654 -2.11662543\n38  -0.061911711  1.94584358\n39  -0.305962664  4.14992767\n40  -0.380471001 -2.59704537\n41  -0.694706979  1.52147983\n42  -0.207917278 -0.13874948\n43  -1.265396352 -3.34025631\n44   2.168955965 -1.33640953\n45   1.207961998 -2.03869325\n46  -1.123108583 -1.17952277\n47  -0.402884835 -2.64509783\n48  -0.466655354  1.61917310\n49   0.779965118  5.12919870\n50  -0.083369066 -2.11991394\n51   0.253318514  2.21480288\n52  -0.028546755  2.02238377\n53  -0.042870457  1.14082641\n54   1.368602284 -0.76402196\n55  -0.225770986  0.13692074\n56   1.516470604  0.77326816\n57  -1.548752804  0.77416502\n58   0.584613750  0.07666005\n59   0.123854244  2.52206661\n60   0.215941569 -0.13039385\n61   0.379639483  2.81422465\n62  -0.502323453 -1.87463191\n63  -0.333207384 -2.20357455\n64  -1.018575383  6.42186341\n65  -1.071791226 -0.92320035\n66   0.303528641  1.26339594\n67   0.448209779  2.01965473\n68   0.053004227 -0.43840893\n69   0.922267468  2.04097120\n70   2.050084686  2.36547563\n71  -0.491031166 -0.20082816\n72  -2.309168876 -0.63945681\n73   1.005738524  0.98502168\n74  -0.709200763  4.36684338\n75  -0.688008616 -1.36107693\n76   1.025571370 -1.12792828\n77  -0.284773007  0.41895164\n78  -1.220717712  0.44956676\n79   0.181303480  1.47276387\n80  -0.138891362 -0.49312091\n81   0.005764186 -1.62348197\n82   0.385280401  3.23827457\n83  -0.370660032 -0.40316379\n84   0.644376549 -0.87661862\n85  -0.220486562 -0.09382675\n86   0.331781964  0.28812829\n87   1.096839013  3.32310204\n88   0.435181491  0.90882440\n89  -0.325931586  1.82884520\n90   1.148807618  0.13326016\n91   0.993503856  1.47531774\n92   0.548396960  0.15224650\n93   0.238731735  0.82046951\n94  -0.627906076 -1.63607506\n95   1.360652449 -1.37324422\n96  -0.600259587  4.16428400\n97   2.187332993  2.90445079\n98   1.532610626 -1.15960688\n99  -0.235700359 -0.85196703\n100 -1.026420900 -2.43549166"
  },
  {
    "objectID": "Basics_1.html#how-do-we-visualize-categorical-data",
    "href": "Basics_1.html#how-do-we-visualize-categorical-data",
    "title": "What are models?",
    "section": "How do we visualize categorical data?",
    "text": "How do we visualize categorical data?\nNominal/categorical data does not have any inherent numbers associated with it. Think control/tx, eye color, etc.\n\n\nCode\nset.seed(123)\ngroup &lt;- c(0, 1)\nx.2 &lt;- rep(group, times = 50)\ne.1 &lt;- rnorm(100, 0, 1)\ny.1 &lt;- .5 + .85 * x.2 + e.1\nd.2 &lt;- data.frame(x.2,y.1)\nm.2 &lt;- lm(y.1 ~ x.2, data = d.2)\nd2.f&lt;- augment(m.2)\nd.2\n\n\n    x.2          y.1\n1     0 -0.060475647\n2     1  1.119822511\n3     0  2.058708314\n4     1  1.420508391\n5     0  0.629287735\n6     1  3.065064987\n7     0  0.960916206\n8     1  0.084938765\n9     0 -0.186852852\n10    1  0.904338030\n11    0  1.724081797\n12    1  1.709813827\n13    0  0.900771451\n14    1  1.460682716\n15    0 -0.055841135\n16    1  3.136913137\n17    0  0.997850478\n18    1 -0.616617157\n19    0  1.201355902\n20    1  0.877208592\n21    0 -0.567823706\n22    1  1.132025085\n23    0 -0.526004448\n24    1  0.621108771\n25    0 -0.125039268\n26    1 -0.336693311\n27    0  1.337787044\n28    1  1.503373118\n29    0 -0.638136937\n30    1  2.603814921\n31    0  0.926464221\n32    1  1.054928517\n33    0  1.395125661\n34    1  2.228133488\n35    0  1.321581082\n36    1  2.038640254\n37    0  1.053917654\n38    1  1.288088289\n39    0  0.194037336\n40    1  0.969528999\n41    0 -0.194706979\n42    1  1.142082722\n43    0 -0.765396352\n44    1  3.518955965\n45    0  1.707961998\n46    1  0.226891417\n47    0  0.097115165\n48    1  0.883344646\n49    0  1.279965118\n50    1  1.266630934\n51    0  0.753318514\n52    1  1.321453245\n53    0  0.457129543\n54    1  2.718602284\n55    0  0.274229014\n56    1  2.866470604\n57    0 -1.048752804\n58    1  1.934613750\n59    0  0.623854244\n60    1  1.565941569\n61    0  0.879639483\n62    1  0.847676547\n63    0  0.166792616\n64    1  0.331424617\n65    0 -0.571791226\n66    1  1.653528641\n67    0  0.948209779\n68    1  1.403004227\n69    0  1.422267468\n70    1  3.400084686\n71    0  0.008968834\n72    1 -0.959168876\n73    0  1.505738524\n74    1  0.640799237\n75    0 -0.188008616\n76    1  2.375571370\n77    0  0.215226993\n78    1  0.129282288\n79    0  0.681303480\n80    1  1.211108638\n81    0  0.505764186\n82    1  1.735280401\n83    0  0.129339968\n84    1  1.994376549\n85    0  0.279513438\n86    1  1.681781964\n87    0  1.596839013\n88    1  1.785181491\n89    0  0.174068414\n90    1  2.498807618\n91    0  1.493503856\n92    1  1.898396960\n93    0  0.738731735\n94    1  0.722093924\n95    0  1.860652449\n96    1  0.749740413\n97    0  2.687332993\n98    1  2.882610626\n99    0  0.264299641\n100   1  0.323579100"
  },
  {
    "objectID": "Basics_1.html#what-do-these-visualizations-have-in-common",
    "href": "Basics_1.html#what-do-these-visualizations-have-in-common",
    "title": "What are models?",
    "section": "What do these visualizations have in common?",
    "text": "What do these visualizations have in common?\n\nLINES!\nMost of what we are going to do is represent the relationship between variables with lines (or planes or hyperplanes once we get into 2 or more variables)"
  },
  {
    "objectID": "Basics_1.html#thinking-in-terms-of-models",
    "href": "Basics_1.html#thinking-in-terms-of-models",
    "title": "What are models?",
    "section": "Thinking in terms of models",
    "text": "Thinking in terms of models\n\nModels help us draw the lines\nOur DV (here forth Y) is what we are trying to understand\nWe hypothesize it has some relationship with your IV(s) (hence forth Xs), with what is left over described as error (E)\n\n\\(y = b_0 + b_{1}X + e\\)\n\n\\(b_{1}\\) describes the strength of association i.e. the line!"
  },
  {
    "objectID": "Basics_1.html#regression-equation",
    "href": "Basics_1.html#regression-equation",
    "title": "What are models?",
    "section": "Regression Equation",
    "text": "Regression Equation\n\\[Y_i = b_{0} + b_{1}X_i +e_i\\]\n\n\\(Y_i \\sim Normal(\\mu, \\sigma)\\)\nThe DV, \\(Y\\) is assumed to be distributed as a Gaussian normal, made up of \\(Y_i\\), with a mean of \\(\\mu\\) and a standard deviation of \\(\\sigma\\)"
  },
  {
    "objectID": "Basics_1.html#regression-terms",
    "href": "Basics_1.html#regression-terms",
    "title": "What are models?",
    "section": "Regression terms",
    "text": "Regression terms\n\nY / DV / Outcome / Response / Criterion\nX / IV / Predictor / Explanatory variable\nRegression coefficient (weight) / b / b* / \\(\\beta\\)\nIntercept \\(b_0\\) / \\(\\beta_{0}\\)\nError / Residuals \\(e\\)\nPredictions \\(\\hat{Y}\\)"
  },
  {
    "objectID": "Basics_1.html#regression-models",
    "href": "Basics_1.html#regression-models",
    "title": "What are models?",
    "section": "Regression models",
    "text": "Regression models\n\nThese models are a way to convey the relationship between two (or more) variables. They translate our hypotheses into math.\nWe can use these models to get information we may be interested in (e.g. means, SEs) and test hypotheses about the relationship among variables\n“All models are wrong but some are useful (and some are better than others)” - George Box"
  },
  {
    "objectID": "Basics_1.html#parts-of-the-model",
    "href": "Basics_1.html#parts-of-the-model",
    "title": "What are models?",
    "section": "Parts of the model",
    "text": "Parts of the model\n\\[Y_i = b_{0} + b_{1}X_i + e_i\\] \\[T.risk_i = b_{0} + b_{1}TX_i + e_i\\]\n\nEach individual has a unique Y value an X value and a residual/error term\n\nThe model only has a single \\(b_{0}\\) and \\(b_{1}\\) term. These are the regression parameters. \\(b_{0}\\) is the intercept and \\(b_{1}\\) quantifies the relationship between your model of the world and the DV."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quant 1",
    "section": "",
    "text": "Welcome to the first day of class! If you want to follow along with examples, head over to github for all of the code and data. https://github.com/josh-jackson/Quant_I_2025\ndf"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Text books\n\nLSR readings can be found in the free, online textbook, Learning Statistics with R by Danielle Navarro.\nStatistical thinking for the 21st century. By Russell A. Poldrack Statistical thinking for the 21st century\n\n\n\nWeekly schedule\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nReadings\nHW Due\n\n\n\n\n1\n8/26\nModels\n\n\n\n\n-\n8/28\nDescribing data\n\n\n\n\n2\n9/2\nGLM basics\nLSR Ch 1 & 3\n\n\n\n-\n9/4\nProbability distributions\nLSR Ch 5 & 6\n\n\n\n3\n9/9\nProbability distributions\nLSR Ch 5 & 6\nHW 1 due\n\n\n-\n9/11\nEstimation, Likelihood & Loss\nLSR Ch 9\n\n\n\n4\n9/16\nEstimation, Likelihood & Loss\nLSR Ch 9\n\n\n\n-\n9/18\nSimple regressions (1 predictor and t-tests)\nLSR Ch 10\n\n\n\n5\n9/23\nExam 1\n\n\n\n\n-\n9/25\nStatistical inference part 1 (Sampling and NHST)\nLSR Ch 11\nHW 2 due\n\n\n6\n9/30\nStatistical inference part 2 (Estimation)\nLSR Ch 11\n\n\n\n-\n10/2\nStatistical inference part 3 (Model comparisons)\nLSR Ch 11\n\n\n\n7\n10/7\nNo Class - Fall Break!\n\n\n\n\n-\n10/9\nSimulation and prediction\n\n\n\n\n8\n10/14\nWhat can go wrong (Transparency and Open science)\nLSR Ch 12\n\n\n\n-\n10/16\nAssumptions\nLSR Ch 13\n\n\n\n9\n10/21\nPower\nLSR Ch 13\n\n\n\n-\n10/23\nVisualizing Data\nLSR Ch 13\n\n\n\n10\n10/28\nThreats to Validity\n\n\n\n\n-\n10/30\nExam 2\n\nHW 3 due\n\n\n11\n11/4\n3 or more means (ANOVA)\n\n\n\n\n-\n11/6\nMultiple comparisons & contrasts\n\n\n\n\n12\n11/11\nInteractions\nLSR Ch 16\n\n\n\n-\n11/13\nANCOVA\n\n\n\n\n13\n11/18\nWithin-subjects designs\nLSR Ch 16\n\n\n\n-\n11/20\nBinomial and logistic regression\n\n\n\n\n14\n11/25\nChi-Square test\n\n\n\n\n-\n11/27\nNo Class – Happy Thanksgiving!\n\n\n\n\n15\n12/2\nEstimation revisited\n\nHW 5 due\n\n\n-\n12/4\nExam 3\n\n\n\n\n\n\n\nOverview\nThis course is the first in a two-course sequence that introduces necessary skills and knowledge for carrying out statistical analyses in the social sciences. The course has an applied focus for psychological research, but theoretical details will be emphasized when they facilitate understanding of key concepts. In other words, we will strike a balance between learning how to do statistics and knowing why we are doing it a particular way. Mastering both will facilitate generalization to new problems and techniques. Topics to be covered this semester include theoretical probability distributions (e.g., binomial, \\(t\\), \\(F\\), \\(\\chi^2\\)), general linear model basics, inferences about population means, confidence intervals, the pros and cons of null hypothesis testing, power, and effect sizes, and ANOVA.\n\nTextbook\nWe will primarily be referring to chapters in Learning Statistics with R by Danielle Navarro. This textbook is available for free online. You may choose to purchase a paper copy if you wish, but it is not required. Additional readings assignments will be posted here.\n\n\nR and RStudio\nStudents must have the latest version of R, which can be downloaded here. It is strongly recommended that students also download the RStudio GUI, available here. Both are free.\n\n\nResources for R and RStudio\nWhile we will be covering the use of R and RStudio extensively, one of the key skills required to use R is the ability to find answers on the Internet. The R community (sometimes referred to as the useR or rstats community) tends to be friendly and helpful and enjoys solving R-related problems in their spare time. For that reason, many common questions or problems have been posted to spaces online and answered by smart people. Finding and deciphering those answers is the key skill you should seek to hone this year. It’s much more important than remembering function names.\nHere’s a resource page to get you going.\n\n\n\nGraded materials\nYour final grade is comprised of three components:\n\n5 Homework: 6% each, 30% total\nExams: 20% for the first exam, 25% for exams 2 and 3, 70% total\n\n\nHomework assignments\nHomework assignments are intended to gauge your ability to apply the topics covered in class to the practice of data analysis. Homework assignments are to be done using R and RMarkdown; completed assignments should be submitted to Canvas. Please submit BOTH your .Rmd and .html file. Please do not use PDF or Word documents. There will be 5 assignments in total, each worth 6% of your grade.\nHWs are due at their due date by 9:30am. Grading will go by the following rubric:\n\n6/6: Completed all parts of the assignment, and results/interpretations were mostly correct (with maybe a few minor errors along the way)\n5/6: Completed all parts of the assignment, and ~25% of the results/interpretations are incorrect\n4/6: Completed all parts of the assignment, however ~50% of the results/interpretations are incorrect\n4/6: Either parts of the assignment are missing but what is there is correct, OR all parts have been completed but there are substantial issues with the results/interpretation\n2/6: Parts of the assignment are missing, and there are substantial issues with the results/interpretation\n1/6: Nearly all of the assignment is missing, but something was turned in\n0/6: No assignment submitted\n\nYou may work with your peers on homework assignments, with the following caveats:\n\nYour code cannot be 100% identical to your peer’s code (trust me, we can tell). It’s one thing to work together and consult, but it’s another thing to copy someone’s assignment. If it is determined that someone copied an entire homework assignment, both parties will be given automatic zero.\nIf you work with someone, you must acknowledge them in the assignment itself.\n\n\n\nExams\nThere will be 3 exams. They will test both your theoretical understanding of concepts, as well as your applied understanding of the material. You will not be expected to open R and code during these exams, however you will be expected to understand R code that has been provided. As exams get closer, I will go over the procedures and policies with you before the exam. If you have a disability that will require additional time, please contact me and Disability Resources as soon as possible (contact information below). The first exam is worth 20% of your grade. Exams 2 and 3 are each worth 25% of your grade.\n\n\nFinal Grading Rubric\nAll assignments and examinations are mandatory. If you need to miss an exam you must get in touch with me as soon as possible. Rescheduling of exams will be considered on a case by case basis, but I am not required to approve a rescheduled exam.\n\\[\\begin{equation}\n\\begin{split}\n\n& \\text{93% &gt;=  A} \\\\\n& \\text{90% - 92.99% = A-} \\\\\n& \\text{87% - 89.99% = B+} \\\\\n& \\text{83% - 86.99% = B} \\\\\n& \\text{80% - 82.99% = B-} \\\\\n& \\text{77% - 79.99% = C+} \\\\\n\n\\end{split}\n\n\\begin{split}\n& \\text{73% - 76.99% = C} \\\\\n& \\text{70% - 72.99% = C-} \\\\\n& \\text{67% - 69.99% = D+} \\\\\n& \\text{63% - 66.99% = D} \\\\\n& \\text{60% - 62.99% = D-} \\\\\n&\\text{&lt; 50% = F}\n\n\\end{split}\n\\end{equation}\\]\n\n\nStaying Connected\n\nWe will have a dedicated class Slack work space (see upper right corner of website for link). You can post questions that everyone can see, or make use of direct messaging. Shelly or the AIs will respond to your questions on Slack (if your peers don’t respond first!). This is really great for one-off questions, or if you need some quick clarification on something. We will also have a dedicated channel for silly programming and stats memes, because humor is important when you’re learning a skill like coding, in which you’ll repeatedly fail. Slack is not required per se, but it is highly encouraged.\nWe will occasionally have group discussions. Please engage with those around you.\n\n\n\nBe Considerate and Kind\n\nIt is OK to not be OK. If you tell me you’re having trouble, I’m not going to judge you or think less of you. I hope you will do the same for me. I will work with you to make sure we have a reasonable plan in place should something come up. However, this does require you telling me “hey, I’m not OK”.\nYou are always welcome to come talk to me about things that you’re going through. If I can’t help you, I usually know someone who can help – or I can at least give you some resources and point you in the right direction.\nIf you are struggling or need extra help, please just ask. I promise I will work with you.\n\n\n\nAttendance & In-person Etiquette\n\nI expect all students to be in class if they are able (not sick, not at a conference etc.). The best way to succeed is to come to class. Your chosen profession requires mastery of these skills! Come to class!\n\nYou are adults. Come to class when you can. Let me know when you can’t (quick email or Slack is OK).\n\nIf you are not feeling well, don’t come to class!! You have access to the slides and you can ask a friend for notes.\nMost people will have electronics with them in class. Drinks should have a lid on them so that if they spill, we hopefully aren’t ruining yours or another person’s laptop/tablet/phone etc. Be careful!\n\n\n\nOnline Etiquette\nThere will be a lot of online communication with the instructor, the AI, and your peers. You are expected to maintain a polite and respectful tone in their online discourse. Some things to consider:\n\nAny communication shared privately may become public, so be mindful of what you share in discussion boards or chats. This is especially true for sharing any personal and/or identifying information about you or someone else. Do not share any passwords or divulge any personal information (yours or others) that can be used in a malicious manner (phone numbers, addresses etc.).\nHumor doesn’t always translate in an online forum. If you want to make a joke or a sarcastic remark, be 100% sure that it is clear you are joking.\nYour comments must be readable to everyone. Very common acronyms are OK (“lol” or “haha”). But please refrain from acronyms that are not as well-known (“fwiw” etc.).\nTreat your classmates, professor, and AIs with kindness and respect. Any indication of online harassment or bullying will not be tolerated and will be reported. This is especially pertinent when giving constructive feedback in code reviews.\nPlease avoid using ALL CAPS because it can be interpreted as yelling.\n\n\n\n\nPolicies & Resources\nUniversity Code of Conduct:\n\nAny student found guilty of academic misconduct, such as cheating, plagiarizing, forgery, or furnishing false information to a University official will be subject to consequences including failing the class, suspension from the University, or expulsion from the University. Frankly, you’re in graduate school, and the purpose of work is to create opportunities to learn and improve. Even if cheating helps you in the short term, you’ll quickly find yourself ill-prepared for the career you have chosen. If you find yourself tempted to cheat, please come speak to me about an extension and developing tools to improve your success.\nPlease see the official University Code of Conduct\n\nSpecial Accommodations:\n\nThis includes but is not limited to a learning, sensory, or physical disability or any other diagnosis that requires special accommodations and/or assistance with lectures, reading, written assignments, and/or exam taking\nContact Disability Resources at disabilityresources@wustl.edu or call 314-935-5970\nPlease also contact me as soon as possible if you need special accommodations. Once I have the Accommodation Letter from Disability Resources, we can discuss ways to modify the course experience for you.\n\nMental & Physical Health:\n\nHabif Health and Wellness Center, email HabifInfo@wustl.edu or call 314-935-6666\n\nWUSTL Police Department:\n\nFor an on campus emergency, call 314-935-5555\nFor an off campus emergency, call 911\n\nRelationship or Sexual Violence (including sexual harassment and stalking):\n\nContact a licensed RSVP counselor (confidential, with some limited information being shared as needed with the appropriate university administrator(s)) at rsvpcenter@wustl.edu or call 314-935-3445\nContact the university’s Title IX Director, Ms. Jessica Kennedy, at jwkennedy@wustl.edu or call 314-935-3118\n\nYou can always come to me! Period. However, if you come to me with any issues surrounding child abuse, suicidal tendencies, or sexual assault, sexual discrimination, sexual harassment, dating violence, domestic violence or stalking, I am required to report these to their appropriate administrators. Washington University faculty and administrators strive to maintain confidentiality, but some information may need to be disclosed when it is a matter of safety."
  },
  {
    "objectID": "Estimation_5.html#today",
    "href": "Estimation_5.html#today",
    "title": "Estimation",
    "section": "Today",
    "text": "Today\n\nHow do I find the regression line\nHow do I evaluate the regression line"
  },
  {
    "objectID": "Estimation_5.html#how-do-i-find-the-regression-line",
    "href": "Estimation_5.html#how-do-i-find-the-regression-line",
    "title": "Estimation",
    "section": "How do I find the regression line?",
    "text": "How do I find the regression line?\n\nFor any given scatter plot, you could propose an infinite number of regression lines to best describe the relationship\nThe likelihood function calculates a value for each of those potential lines and tells you which are most “likely”"
  },
  {
    "objectID": "Estimation_5.html#ordinary-least-squares",
    "href": "Estimation_5.html#ordinary-least-squares",
    "title": "Estimation",
    "section": "Ordinary least squares",
    "text": "Ordinary least squares"
  },
  {
    "objectID": "Estimation_5.html#when-ols-doesnt-work",
    "href": "Estimation_5.html#when-ols-doesnt-work",
    "title": "Estimation",
    "section": "When OLS doesn’t work",
    "text": "When OLS doesn’t work\n\nOLS is"
  },
  {
    "objectID": "Estimation_5.html#log-likelihood",
    "href": "Estimation_5.html#log-likelihood",
    "title": "Estimation",
    "section": "Log Likelihood",
    "text": "Log Likelihood\n\nMaximizing the log-likelihood is the same as maximizing the likelihood, but it’s mathematically and computationally much easier.\nLikelihood of observing all your data points is the product of the likelihood of each individual point. Multiplying many small probs will lead to issues. So we log them to turn it into addition.\nFor likelihood, the data are treated as a given, and value of theta varies. L(θ | data )"
  },
  {
    "objectID": "Estimation_5.html#log-likelihood-example",
    "href": "Estimation_5.html#log-likelihood-example",
    "title": "Estimation",
    "section": "Log Likelihood example",
    "text": "Log Likelihood example\n\ncalculate a mean and SD"
  },
  {
    "objectID": "Estimation_5.html#log-likelihood-example-1",
    "href": "Estimation_5.html#log-likelihood-example-1",
    "title": "Estimation",
    "section": "Log Likelihood example",
    "text": "Log Likelihood example\n\ndefine what values we want to calculate log likelihood for\n\n\nlibrary(psychTools)\nlibrary(tidyr)\nlibrary(tidyverse)\ngalton.data &lt;- galton\ngrid &lt;-\n  crossing(mu = seq(from = 66, to = 69, length.out = 200), sigma = seq(from = 2, to = 3, length.out = 200))\ngrid\n\n# A tibble: 40,000 × 2\n      mu sigma\n   &lt;dbl&gt; &lt;dbl&gt;\n 1    66  2   \n 2    66  2.01\n 3    66  2.01\n 4    66  2.02\n 5    66  2.02\n 6    66  2.03\n 7    66  2.03\n 8    66  2.04\n 9    66  2.04\n10    66  2.05\n# ℹ 39,990 more rows"
  },
  {
    "objectID": "Estimation_5.html#log-likelihood-example-2",
    "href": "Estimation_5.html#log-likelihood-example-2",
    "title": "Estimation",
    "section": "Log Likelihood example",
    "text": "Log Likelihood example\n\nNeed to calcualte the log likelihood of our data (each child’s height) assuming each part of our grid is true.\nTake the first line of our grid (mu = 66, sigma = 2) so we can see how likely each child (all 928) by dnorm(height, 66, 2)\nWe sum the LLs across all 928 participants for each spot in the grid to get the average log-likelihood for each grid spot"
  },
  {
    "objectID": "Estimation_5.html#model-fit",
    "href": "Estimation_5.html#model-fit",
    "title": "Estimation",
    "section": "Model fit",
    "text": "Model fit\n\nThe way the world is = our model + error\nHow good is our model? Is it a good representation of reality? Does it “fit” the data well?\nNeed to go beyond asking if it is significant, because what does that mean? Remember, all models are wrong\nWe are going to make predictions and see if the predictions (based on our model) matches our data"
  },
  {
    "objectID": "Estimation_5.html#model-fit-1",
    "href": "Estimation_5.html#model-fit-1",
    "title": "Estimation",
    "section": "Model fit",
    "text": "Model fit\n\nOur model is a prediction machine.\nThey are created by simply plugging a persons Xs into the created model\nIf you have bs and have Xs you can create a prediction\n\n\\(\\hat{Y}_{i}\\) = 2.65064 + -0.48111* \\(X_{i}\\)"
  },
  {
    "objectID": "Estimation_5.html#model-fit-2",
    "href": "Estimation_5.html#model-fit-2",
    "title": "Estimation",
    "section": "Model fit",
    "text": "Model fit\n\nWe want our predictions to be close to our actual data for each person ( \\(Y_{i}\\) )\nThe difference between the actual data and our our prediction ( \\(Y_{i} - \\hat{Y}_{i} = e\\) ) is the residual, how far we are “off”. This tells us how good our fit is.\nYou can have the same estimates for two models but completely different fit."
  },
  {
    "objectID": "Estimation_5.html#model-fit-3",
    "href": "Estimation_5.html#model-fit-3",
    "title": "Estimation",
    "section": "Model fit",
    "text": "Model fit\n\nCan you point out the predictions?\n\n\n\nCode\ntwogroup_fun = function(nrep = 100, b0 = 6, b1 = -2, sigma = 1) {\n     ngroup = 2\n     group = rep( c(\"group1\", \"group2\"), each = nrep)\n     eps = rnorm(ngroup*nrep, 0, sigma)\n     traffic = b0 + b1*(group == \"group2\") + eps\n     growthfit = lm(traffic ~ group)\n     growthfit\n}\n\n\ntwogroup_fun2 = function(nrep = 100, b0 = 6, b1 = -2, sigma = 2) {\n     ngroup = 2\n     group = rep( c(\"group1\", \"group2\"), each = nrep)\n     eps = rnorm(ngroup*nrep, 0, sigma)\n     traffic = b0 + b1*(group == \"group2\") + eps\n     growthfit = lm(traffic ~ group)\n     growthfit\n}\n\nset.seed(16)\nlibrary(broom)\nlm1 &lt;- augment(twogroup_fun())\n\nset.seed(16)\nlm2 &lt;- augment(twogroup_fun2())\n\nplot1&lt;- ggplot(lm1) +\n  aes(x = group, y = traffic) +\n  geom_violin() + geom_boxplot() + geom_jitter() + ylim(-1, 11)\n\nplot2&lt;- ggplot(lm2) +\n  aes(x = group, y = traffic) +\n  geom_violin() + geom_boxplot() + geom_jitter() + ylim(-1, 11)\n\n\nlibrary(gridExtra)\n grid.arrange(plot1, plot2, ncol=2)"
  },
  {
    "objectID": "Estimation_5.html#same-plot-with-continuous",
    "href": "Estimation_5.html#same-plot-with-continuous",
    "title": "Estimation",
    "section": "Same plot with continuous",
    "text": "Same plot with continuous"
  },
  {
    "objectID": "Estimation_5.html#partitioning-variance",
    "href": "Estimation_5.html#partitioning-variance",
    "title": "Estimation",
    "section": "Partitioning variance",
    "text": "Partitioning variance\n\\[\\sum (Y - \\bar{Y})^2 = \\sum (\\hat{Y} -\\bar{Y})^2 + \\sum(Y - \\hat{Y})^2\\]"
  },
  {
    "objectID": "Estimation_5.html#sigma",
    "href": "Estimation_5.html#sigma",
    "title": "Estimation",
    "section": "Sigma",
    "text": "Sigma"
  }
]